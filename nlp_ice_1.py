# -*- coding: utf-8 -*-
"""NLP ICE 1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dPeBFLvV11jWLZnqmBK4HkLXRA-9AL3g
"""

from bs4 import BeautifulSoup
import matplotlib
import urllib.request

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
import pandas as pd
import seaborn as sns

response = urllib.request.urlopen('https://en.wikipedia.org/wiki/SpaceX')

html = response.read()

soup = BeautifulSoup(html, "html5lib")

text = soup.get_text(strip=True)

tokens = [t for t in text.split()]

clean_tokens = tokens[:]

sr = stopwords.words('english')

# Remove stopwords from file
for token in tokens:
    if token in sr:
        clean_tokens.remove(token)

# Add frequency to dictionary
freq = nltk.FreqDist(clean_tokens)

# Remove value of a key less than 5
for key, values in list(freq.items()):
    if values < 5:
        del freq[key]

sorted(freq.items(), key=lambda item: item[1], reverse=True)  

# print top 10 distribution words
freq.plot(10, cumulative=False)  # print 10 high frequency keywords

# Code to create another visual for word frequency

dict_variable = {key:value for (key,value) in freq.items()}
data = pd.DataFrame.from_dict(dict_variable, orient='index')
data = data.reset_index()
data.columns = ['word', 'frequency']
data.sort_values(by=['frequency'], inplace=True, ascending=False)

ax = sns.barplot(x="word", y="frequency", data=data[0:10])
ax.tick_params(axis='x', rotation=90)